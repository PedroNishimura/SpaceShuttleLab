{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1988c15-76ba-4563-8677-c3608a055c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /usr/local/spark-3.3.1-bin-hadoop3/python (3.3.1)\n",
      "Requirement already satisfied: psycopg2-binary in /opt/conda/lib/python3.10/site-packages (2.9.10)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c40cb75-775b-4343-b354-6f3211556d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, BooleanType, TimestampType, ShortType\n",
    "from pyspark.sql.functions import to_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08adc524-516c-476c-a031-9184d315fdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_spark_session():    \n",
    "    try:\n",
    "        spark = SparkSession.builder \\\n",
    "            .appName(\"PostgreSQL\") \\\n",
    "            .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.2.20\") \\\n",
    "            .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:1.0.0\") \\\n",
    "            .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "            .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "        spark.conf.set(\"spark.hadoop.fs.s3a.access.key\", \"datalake\")\n",
    "        spark.conf.set(\"spark.hadoop.fs.s3a.secret.key\", \"datalake\")\n",
    "        spark.conf.set(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "        spark.conf.set(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "        spark.conf.set(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "        print(\"Sessão Spark criada com sucesso!\")\n",
    "\n",
    "        return spark\n",
    "    except Exception as err:\n",
    "        print(\"Something went wrong trying to create or get spark session!\")\n",
    "        print(f\"ERROR: {err}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bb54d55-0b4d-499c-808d-02655514e865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessão Spark criada com sucesso!\n"
     ]
    }
   ],
   "source": [
    "spark = init_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c1a670e-0433-4cb6-98cd-247f19c08173",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"delta\").load(\"s3a://raw/position\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2480735-f0e6-4187-999c-9bf4df22a88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados escritos com sucesso na tabela PostgreSQL!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_timestamp, col\n",
    "\n",
    "df = df \\\n",
    "    .withColumnRenamed(\"hora\", \"hora_info\")\\\n",
    "    .withColumnRenamed(\"utc\", \"data_hora\")\\\n",
    "    .withColumn(\"hora_info\", col(\"hora_info\").cast(\"string\")) \\\n",
    "    .withColumn(\"cd_linha\", col(\"cd_linha\").cast(\"integer\")) \\\n",
    "    .withColumn(\"sentido\", col(\"sentido\").cast(\"short\")) \\\n",
    "    .withColumn(\"quantidade_veiculos\", col(\"quantidade_veiculos\").cast(\"integer\")) \\\n",
    "    .withColumn(\"flag_acessivel\", col(\"flag_acessivel\").cast(\"boolean\")) \\\n",
    "    .withColumn(\"data_hora\", to_timestamp(\"data_hora\")) \\\n",
    "    .withColumn(\"latitude_veiculo\", col(\"latitude_veiculo\").cast(\"string\")) \\\n",
    "    .withColumn(\"longitude_veiculo\", col(\"longitude_veiculo\").cast(\"string\"))\n",
    "\n",
    "jdbc_url = \"jdbc:postgresql://db:5432/spacedb\"\n",
    "properties = {\n",
    "    \"user\": \"spacedb\",\n",
    "    \"password\": \"spacedb\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "# Escrever dados no PostgreSQL\n",
    "df.write.jdbc(url=jdbc_url, table=\"sparcedb.posicao\", mode=\"append\", properties=properties)\n",
    "\n",
    "print(\"Dados escritos com sucesso na tabela PostgreSQL!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
