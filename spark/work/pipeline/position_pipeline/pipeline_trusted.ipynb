{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e671c4e4-e507-4ee2-928e-46791217ae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./sessions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e241c53-ab98-4458-b5c9-6178c727a627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b643d724-82f5-4c49-b660-6b5b1dd104c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_data(df):\n",
    "    df = df.withColumn(\"l\", explode(df.l))\n",
    "    return df.withColumn(\"vs\", explode(df.l.vs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e63a425-0088-449d-bc90-98edbf5b950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_formatter(df):\n",
    "    df = df.withColumnRenamed(\"hr\", \"hora\") \\\n",
    "                  .withColumn(\"codigo_empresa\", col(\"l.c\")) \\\n",
    "                  .withColumn(\"codigo_linha\", col(\"l.cl\")) \\\n",
    "                  .withColumn(\"sentido_operacao\", col(\"l.sl\")) \\\n",
    "                  .withColumn(\"destino_linha\", col(\"l.lt0\")) \\\n",
    "                  .withColumn(\"origem_linha\", col(\"l.lt1\")) \\\n",
    "                  .withColumn(\"veiculos_circulacao\", col(\"l.qv\")) \\\n",
    "                  .withColumn(\"prefixo_veiculo\", col(\"vs.p\")) \\\n",
    "                  .withColumn(\"flag_acessivel\", col(\"vs.a\")) \\\n",
    "                  .withColumn(\"data_hora\", col(\"vs.ta\")) \\\n",
    "                  .withColumn(\"latitude\", col(\"vs.py\")) \\\n",
    "                  .withColumn(\"longitude\", col(\"vs.px\"))\n",
    "\n",
    "    return df.drop(\"l\",\"vs\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43bd5eb1-75db-43d5-9520-3289909996cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_position_trusted_job():\n",
    "    print(\"Obtendo sessão spark e lendo os dados da Raw.\")\n",
    "    spark = get_or_create_session_spark(\"space_shuttle\")\n",
    "    df = spark.read.format(\"delta\").load(\"s3a://raw/position\")\n",
    "    print(f\"Dados lidos! Tamanho do dataframe {df.count()}\")\n",
    "    \n",
    "    if df != None or df.count() == 0:\n",
    "        print(\"Iniciando a formatação dos dados.\")\n",
    "        df = explode_data(df)\n",
    "        df = output_formatter(df)\n",
    "        print(\"Dados formatados!\")\n",
    "        \n",
    "        print(\"Realizando a escrita dos dados na camada Trusted.\")\n",
    "        df.write.format(\"delta\").mode(\"append\").save(\"s3a://trusted/position\")\n",
    "        print(\"Processamento raw to trusted finalizado com sucesso!\")\n",
    "    else:\n",
    "        print(\"Dados não encontrados!\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
