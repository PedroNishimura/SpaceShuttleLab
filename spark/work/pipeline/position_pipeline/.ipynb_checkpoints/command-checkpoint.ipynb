{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4228d4f5-44c6-4731-bb7a-ecd41fafa5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./pipeline_raw.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf4ee47c-c34d-49ba-8ba6-6b2045167135",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./pipeline_trusted.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c758295-3f31-48f7-8d11-92a1a87a53f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: schedule in /opt/conda/lib/python3.10/site-packages (1.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd04f2f6-3595-4197-a644-9b27fbcbc432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import schedule\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "275f3a38-e6f7-4eae-acf4-70b5c3ba6c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def job():\n",
    "    run_position_job()\n",
    "    run_position_trusted_job()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0a808b-bd1a-4067-9258-c742e4f4a2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessão Spark criada com sucesso! space_shuttle\n",
      "Obtendo sessão spark e lendo os dados da Raw.\n",
      "Sessão Spark criada com sucesso! space_shuttle\n",
      "Dados lidos! Tamanho do dataframe 1\n",
      "Iniciando a formatação dos dados.\n",
      "Dados formatados!\n",
      "Realizando a escrita dos dados na camada Trusted.\n",
      "Processamento raw to trusted finalizado com sucesso!\n",
      "Sessão Spark criada com sucesso! space_shuttle\n",
      "Obtendo sessão spark e lendo os dados da Raw.\n",
      "Sessão Spark criada com sucesso! space_shuttle\n",
      "Dados lidos! Tamanho do dataframe 2\n",
      "Iniciando a formatação dos dados.\n",
      "Dados formatados!\n",
      "Realizando a escrita dos dados na camada Trusted.\n",
      "Processamento raw to trusted finalizado com sucesso!\n",
      "Sessão Spark criada com sucesso! space_shuttle\n",
      "Obtendo sessão spark e lendo os dados da Raw.\n",
      "Sessão Spark criada com sucesso! space_shuttle\n",
      "Dados lidos! Tamanho do dataframe 3\n",
      "Iniciando a formatação dos dados.\n",
      "Dados formatados!\n",
      "Realizando a escrita dos dados na camada Trusted.\n",
      "Processamento raw to trusted finalizado com sucesso!\n",
      "Sessão Spark criada com sucesso! space_shuttle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "RuntimeError: reentrant call inside <_io.BufferedReader name=48>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/opt/conda/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/usr/local/spark/python/pyspark/context.py\", line 362, in signal_handler\n",
      "    self.cancelAllJobs()\n",
      "  File \"/usr/local/spark/python/pyspark/context.py\", line 1447, in cancelAllJobs\n",
      "    self._jsc.sc().cancelAllJobs()\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\", line 1321, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/usr/local/spark/python/pyspark/sql/utils.py\", line 190, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling o33.sc\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Não foi possível realizar a ingestão!\n",
      "Erro: An error occurred while calling o247.save\n",
      "Obtendo sessão spark e lendo os dados da Raw.\n",
      "Sessão Spark criada com sucesso! space_shuttle\n",
      "Dados lidos! Tamanho do dataframe 3\n",
      "Iniciando a formatação dos dados.\n",
      "Dados formatados!\n",
      "Realizando a escrita dos dados na camada Trusted.\n",
      "Processamento raw to trusted finalizado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "schedule.every(1).minutes.do(job)\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
